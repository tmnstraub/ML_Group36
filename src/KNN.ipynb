{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_selection import RFE\n",
    "from Preprocessing_functions import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z6/_vn8cndd4x5dmx2cpjfdkjdr0000gn/T/ipykernel_30731/3470921380.py:1: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n",
    "test_data = pd.read_csv('test_data.csv', index_col='Claim Identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accident Date                          23134\n",
       "Age at Injury                          19445\n",
       "Alternative Dispute Resolution         19445\n",
       "Assembly Date                              0\n",
       "Attorney/Representative                19445\n",
       "Average Weekly Wage                    48096\n",
       "Birth Year                             48523\n",
       "C-2 Date                               34005\n",
       "C-3 Date                              406226\n",
       "Carrier Name                           19445\n",
       "Carrier Type                           19445\n",
       "Claim Injury Type                      19445\n",
       "County of Injury                       19445\n",
       "COVID-19 Indicator                     19445\n",
       "District Name                          19445\n",
       "First Hearing Date                    442673\n",
       "Gender                                 19445\n",
       "IME-4 Count                           460668\n",
       "Industry Code                          29403\n",
       "Industry Code Description              29403\n",
       "Medical Fee Region                     19445\n",
       "OIICS Nature of Injury Description    593471\n",
       "WCIO Cause of Injury Code              35085\n",
       "WCIO Cause of Injury Description       35085\n",
       "WCIO Nature of Injury Code             35102\n",
       "WCIO Nature of Injury Description      35102\n",
       "WCIO Part Of Body Code                 36527\n",
       "WCIO Part Of Body Description          36527\n",
       "Zip Code                               48082\n",
       "Agreement Reached                      19445\n",
       "WCB Decision                           19445\n",
       "Number of Dependents                   19445\n",
       "dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[~(train_data.drop(columns=['Assembly Date']).isna().all(axis=1) & train_data['Assembly Date'].notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['Claim Injury Type', 'WCB Decision', 'Agreement Reached'])\n",
    "y = train_data['Claim Injury Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_COLUMNS = ['Industry Code', 'WCIO Cause of Injury Code',\n",
    "       'WCIO Nature of Injury Code', 'WCIO Part Of Body Code']\n",
    "\n",
    "DESCRIPTION_COLUMNS = ['WCIO Cause of Injury Description','WCIO Nature of Injury Description','WCIO Part Of Body Description','Industry Code Description']\n",
    "\n",
    "BOOLEAN_COLUMNS = ['Alternative Dispute Resolution', 'Attorney/Representative','COVID-19 Indicator']\n",
    "\n",
    "date_order = ['Accident Date', 'C-2 Date','C-3 Date','Assembly Date', 'First Hearing Date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    'Accident Date', \n",
    "    'Age at Injury', \n",
    "    'Assembly Date', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year', \n",
    "    'C-2 Date', \n",
    "    'C-3 Date', \n",
    "    'First Hearing Date', \n",
    "    'IME-4 Count', \n",
    "]\n",
    "\n",
    "categorical_features = ['Alternative Dispute Resolution',\n",
    " 'Attorney/Representative',\n",
    " 'Carrier Name',\n",
    " 'Carrier Type',\n",
    " 'County of Injury',\n",
    " 'COVID-19 Indicator',\n",
    " 'District Name',\n",
    " 'Gender',\n",
    " 'Industry Code',\n",
    " 'Medical Fee Region',\n",
    " 'WCIO Cause of Injury Code',\n",
    " 'WCIO Nature of Injury Code',\n",
    " 'WCIO Part Of Body Code',\n",
    " 'Zip Code']\n",
    "\n",
    "col_minmax = ['Age at Injury',\n",
    "               'Birth Year', \n",
    "               'Number of Dependents']\n",
    "\n",
    "col_standart = ['Accident Date',\n",
    "                'Assembly Date',\n",
    "                'Average Weekly Wage',\n",
    "                ]\n",
    "\n",
    "low_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() < 10]\n",
    "high_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() > 10]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carrier Name',\n",
       " 'County of Injury',\n",
       " 'Industry Code',\n",
       " 'WCIO Cause of Injury Code',\n",
       " 'WCIO Nature of Injury Code',\n",
       " 'WCIO Part Of Body Code',\n",
       " 'Zip Code']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_cardinality_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
    "X_val[categorical_features] = X_val[categorical_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_description_columns(X_train, X_val):\n",
    "    \"\"\"\n",
    "    Drop all columns in X_train and X_val that contain the word 'description' in their names (case-insensitive).\n",
    "    \"\"\"\n",
    "    description_columns = X_train.columns[X_train.columns.str.contains('description', case=False, na=False)]\n",
    "    \n",
    "\n",
    "    X_train = X_train.drop(description_columns, axis=1)\n",
    "    X_val = X_val.drop(description_columns, axis=1)\n",
    "    \n",
    "    return X_train, X_val\n",
    "\n",
    "X_train ,X_val = drop_description_columns(X_train, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philippedutranoit/document ordi/nova/machine learning /project/ML_Group36/src/Preprocessing_functions.py:320: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  def impute_mode_categorical(X_train, X_val, columns):\n",
      "/Users/philippedutranoit/document ordi/nova/machine learning /project/ML_Group36/src/Preprocessing_functions.py:321: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 459220 entries, 5785935 to 6027959\n",
      "Data columns (total 45 columns):\n",
      " #   Column                                                    Non-Null Count   Dtype  \n",
      "---  ------                                                    --------------   -----  \n",
      " 0   Accident Date                                             459220 non-null  float64\n",
      " 1   Age at Injury                                             459220 non-null  float64\n",
      " 2   Assembly Date                                             459220 non-null  float64\n",
      " 3   Average Weekly Wage                                       459220 non-null  float64\n",
      " 4   Birth Year                                                459220 non-null  float64\n",
      " 5   C-2 Date                                                  459220 non-null  float64\n",
      " 6   C-3 Date                                                  459220 non-null  float64\n",
      " 7   First Hearing Date                                        459220 non-null  float64\n",
      " 8   IME-4 Count                                               459220 non-null  float64\n",
      " 9   Number of Dependents                                      459220 non-null  float64\n",
      " 10  Has C-3 Date                                              459220 non-null  int64  \n",
      " 11  Has C-2 Date                                              459220 non-null  int64  \n",
      " 12  Has First Hearing Date                                    459220 non-null  int64  \n",
      " 13  Alternative Dispute Resolution_False                      459220 non-null  float64\n",
      " 14  Alternative Dispute Resolution_True                       459220 non-null  float64\n",
      " 15  Alternative Dispute Resolution_nan                        459220 non-null  float64\n",
      " 16  Attorney/Representative_False                             459220 non-null  float64\n",
      " 17  Attorney/Representative_True                              459220 non-null  float64\n",
      " 18  Carrier Type_1A. PRIVATE                                  459220 non-null  float64\n",
      " 19  Carrier Type_2A. SIF                                      459220 non-null  float64\n",
      " 20  Carrier Type_3A. SELF PUBLIC                              459220 non-null  float64\n",
      " 21  Carrier Type_4A. SELF PRIVATE                             459220 non-null  float64\n",
      " 22  Carrier Type_5A. SPECIAL FUND - CONS. COMM. (SECT. 25-A)  459220 non-null  float64\n",
      " 23  Carrier Type_5C. SPECIAL FUND - POI CARRIER WCB MENANDS   459220 non-null  float64\n",
      " 24  Carrier Type_5D. SPECIAL FUND - UNKNOWN                   459220 non-null  float64\n",
      " 25  Carrier Type_UNKNOWN                                      459220 non-null  float64\n",
      " 26  COVID-19 Indicator_False                                  459220 non-null  float64\n",
      " 27  COVID-19 Indicator_True                                   459220 non-null  float64\n",
      " 28  District Name_ALBANY                                      459220 non-null  float64\n",
      " 29  District Name_BINGHAMTON                                  459220 non-null  float64\n",
      " 30  District Name_BUFFALO                                     459220 non-null  float64\n",
      " 31  District Name_HAUPPAUGE                                   459220 non-null  float64\n",
      " 32  District Name_NYC                                         459220 non-null  float64\n",
      " 33  District Name_ROCHESTER                                   459220 non-null  float64\n",
      " 34  District Name_STATEWIDE                                   459220 non-null  float64\n",
      " 35  District Name_SYRACUSE                                    459220 non-null  float64\n",
      " 36  Gender_F                                                  459220 non-null  float64\n",
      " 37  Gender_M                                                  459220 non-null  float64\n",
      " 38  Gender_U                                                  459220 non-null  float64\n",
      " 39  Gender_X                                                  459220 non-null  float64\n",
      " 40  Medical Fee Region_I                                      459220 non-null  float64\n",
      " 41  Medical Fee Region_II                                     459220 non-null  float64\n",
      " 42  Medical Fee Region_III                                    459220 non-null  float64\n",
      " 43  Medical Fee Region_IV                                     459220 non-null  float64\n",
      " 44  Medical Fee Region_UK                                     459220 non-null  float64\n",
      "dtypes: float64(42), int64(3)\n",
      "memory usage: 161.2 MB\n"
     ]
    }
   ],
   "source": [
    "def preprocessing_dum(X_train, X_val):\n",
    "    drop_description_columns(X_train, X_val)\n",
    "    convert_to_timestamp(X_train, X_val, date_order)\n",
    "    convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "    impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    fill_missing_with_mode(X_train, X_val)\n",
    "    feature_creation_has_Cdate(X_train, X_val)\n",
    "\n",
    "\n",
    "    return X_train, X_val\n",
    "\n",
    "\n",
    "\n",
    "def scaling_encoding(X_train, X_val):\n",
    "    scaling_minmax(X_train, X_val, col_minmax)\n",
    "    scaling_standard(X_train, X_val, col_standart)\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train = X_train.drop(columns=high_cardinality_cols)\n",
    "    X_val = X_val.drop(columns=high_cardinality_cols)\n",
    "\n",
    "    return X_train, X_val\n",
    "\n",
    "X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "\n",
    "X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "\n",
    "X_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef preprocessing_complex(X_train, X_val):\\n    convert_to_timestamp(X_train, X_val, date_order)\\n    convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\\n    impute_mean_numerical(X_train, X_val, ['C-2 Date'])\\n    fillna_zip_code(X_train, X_val)\\n    fillnan_accident_date(X_train,X_val)\\n    fillnan_birth_year(X_train,X_val)\\n    feature_creation_has_Cdate (X_train, X_val)\\n    fill_missing_with_mode(X_train, X_val)\\n    drop_description_columns(X_train, X_val)\\n    scaling_standard(X_train, X_val, columns)\\n    encoding_onehot(X_train, X_val, columns)\\n    return X_train, X_val\\npreprocessing_complex(X_train, X_val)\\n\\nX_train.info()\\n\""
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "def preprocessing_complex(X_train, X_val):\n",
    "    convert_to_timestamp(X_train, X_val, date_order)\n",
    "    convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "    impute_mean_numerical(X_train, X_val, ['C-2 Date'])\n",
    "    fillna_zip_code(X_train, X_val)\n",
    "    fillnan_accident_date(X_train,X_val)\n",
    "    fillnan_birth_year(X_train,X_val)\n",
    "    feature_creation_has_Cdate (X_train, X_val)\n",
    "    fill_missing_with_mode(X_train, X_val)\n",
    "    drop_description_columns(X_train, X_val)\n",
    "    scaling_standard(X_train, X_val, columns)\n",
    "    encoding_onehot(X_train, X_val, columns)\n",
    "    return X_train, X_val\n",
    "preprocessing_complex(X_train, X_val)\n",
    "\n",
    "X_train.info()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philippedutranoit/document ordi/nova/machine learning /project/ML_Group36/src/Preprocessing_functions.py:320: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  def impute_mode_categorical(X_train, X_val, columns):\n",
      "/Users/philippedutranoit/document ordi/nova/machine learning /project/ML_Group36/src/Preprocessing_functions.py:321: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  \"\"\"\n",
      "/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = X.reset_index(drop=True) \n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "\n",
    "k_range = range(1, 10)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "mean_f1_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    f1_scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "        X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "        X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "        \n",
    "        X_train_selected, selected_features, feature_ranking = feature_selection_rfe(X_train, y_train, 10, LogisticRegression())\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train_selected, y_train)\n",
    "        \n",
    "        y_pred = knn.predict(X_val[selected_features])\n",
    "        f1 = f1_score(y_val, y_pred, average='macro')\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    mean_f1_scores.append(np.mean(f1_scores))\n",
    "\n",
    "\n",
    "optimal_k = k_range[np.argmax(mean_f1_scores)]\n",
    "print(f\"The optimal number of neighbors is {optimal_k}.\")\n",
    "\n",
    "plt.plot(k_range, mean_f1_scores)\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Mean F1 Score')\n",
    "plt.title('Optimal k Selection using K-Fold Cross-Validation')\n",
    "plt.show()\n",
    "\n",
    "X_preprocessed, _ = preprocessing_dum(X, X)\n",
    "X_scaled, _ = scaling_encoding(X_preprocessed, X_preprocessed)\n",
    "selector = RFE(estimator=LogisticRegression(), n_features_to_select=10)\n",
    "X_final = selector.fit_transform(X_scaled, y)\n",
    "final_knn = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "final_knn.fit(X_final, y)\n",
    "\n",
    "print(f\"Model trained with optimal k={optimal_k}.\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Range of k values to test (for XGBoost, we can try different hyperparameters)\n",
    "learning_rate_range = [0.01, 0.1, 0.3, 0.5, 0.7]\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# To store mean accuracy for each learning rate\n",
    "mean_accuracies = []\n",
    "\n",
    "# Perform K-Fold for each learning rate\n",
    "for learning_rate in learning_rate_range:\n",
    "    accuracies = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Split the data into training and test sets for this fold\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train the XGBoost model\n",
    "        model = XGBClassifier(learning_rate=learning_rate, use_label_encoder=False, eval_metric='mlogloss')\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    # Compute the mean accuracy for this learning rate\n",
    "    mean_accuracies.append(np.mean(accuracies))\n",
    "\n",
    "# Find the optimal learning rate\n",
    "optimal_lr = learning_rate_range[np.argmax(mean_accuracies)]\n",
    "print(f\"The optimal learning rate is {optimal_lr}.\")\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(learning_rate_range, mean_accuracies)\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Optimal Learning Rate Selection using K-Fold Cross-Validation (XGBoost)')\n",
    "plt.show()\n",
    "\n",
    "# Final training with optimal learning rate\n",
    "final_model = XGBClassifier(learning_rate=optimal_lr, use_label_encoder=False, eval_metric='mlogloss')\n",
    "final_model.fit(X, y)\n",
    "print(f\"Model trained with optimal learning rate={optimal_lr}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
