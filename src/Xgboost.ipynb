{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.svm import SVC\n",
    "from Preprocessing_functions import *\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inesm\\AppData\\Local\\Temp\\ipykernel_22120\\3470921380.py:1: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n",
    "test_data = pd.read_csv('test_data.csv', index_col='Claim Identifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and validation sets\n",
    "train_data = train_data[~(train_data.drop(columns=['Assembly Date']).isna().all(axis=1) & train_data['Assembly Date'].notna())] \n",
    "X = train_data.drop(columns=['Claim Injury Type', 'WCB Decision', 'Agreement Reached'])\n",
    "y = train_data['Claim Injury Type']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_COLUMNS = ['Industry Code', 'WCIO Cause of Injury Code',\n",
    "       'WCIO Nature of Injury Code', 'WCIO Part Of Body Code']\n",
    "\n",
    "DESCRIPTION_COLUMNS = ['WCIO Cause of Injury Description','WCIO Nature of Injury Description','WCIO Part Of Body Description','Industry Code Description']\n",
    "\n",
    "BOOLEAN_COLUMNS = ['Alternative Dispute Resolution', 'Attorney/Representative','COVID-19 Indicator']\n",
    "\n",
    "date_order = ['Accident Date', 'C-2 Date','C-3 Date','Assembly Date', 'First Hearing Date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    'Accident Date', \n",
    "    'Age at Injury', \n",
    "    'Assembly Date', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year', \n",
    "    'C-2 Date', \n",
    "    'C-3 Date', \n",
    "    'First Hearing Date', \n",
    "    'IME-4 Count', \n",
    "]\n",
    "\n",
    "categorical_features = ['Alternative Dispute Resolution',\n",
    " 'Attorney/Representative',\n",
    " 'Carrier Name',\n",
    " 'Carrier Type',\n",
    " 'County of Injury',\n",
    " 'COVID-19 Indicator',\n",
    " 'District Name',\n",
    " 'Gender',\n",
    " 'Industry Code',\n",
    " 'Medical Fee Region',\n",
    " 'WCIO Cause of Injury Code',\n",
    " 'WCIO Nature of Injury Code',\n",
    " 'WCIO Part Of Body Code',\n",
    " 'Zip Code']\n",
    "\n",
    "col_minmax = ['Age at Injury',\n",
    "               'Birth Year', \n",
    "               'Number of Dependents']\n",
    "\n",
    "col_standart = ['Accident Date',\n",
    "                'Assembly Date',\n",
    "                'Average Weekly Wage',\n",
    "                ]\n",
    "\n",
    "low_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() < 10]\n",
    "high_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() > 10]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carrier Name',\n",
       " 'County of Injury',\n",
       " 'Industry Code',\n",
       " 'WCIO Cause of Injury Code',\n",
       " 'WCIO Nature of Injury Code',\n",
       " 'WCIO Part Of Body Code',\n",
       " 'Zip Code']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_cardinality_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
    "X_val[categorical_features] = X_val[categorical_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_description_columns(X_train, X_val):\n",
    "    \"\"\"\n",
    "    Drop all columns in X_train and X_val that contain the word 'description' in their names (case-insensitive).\n",
    "    \"\"\"\n",
    "    description_columns = X_train.columns[X_train.columns.str.contains('description', case=False, na=False)]\n",
    "    \n",
    "\n",
    "    X_train = X_train.drop(description_columns, axis=1)\n",
    "    X_val = X_val.drop(description_columns, axis=1)\n",
    "    \n",
    "    return X_train, X_val\n",
    "\n",
    "X_train ,X_val = drop_description_columns(X_train, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_description_columns_Test(X_test):\n",
    "    \"\"\"\n",
    "    Drop all columns in X_train and X_val that contain the word 'description' in their names (case-insensitive).\n",
    "    \"\"\"\n",
    "    description_columns = X_test.columns[X_test.columns.str.contains('description', case=False, na=False)]\n",
    "    \n",
    "\n",
    "    X_test = X_test.drop(description_columns, axis=1)\n",
    "    \n",
    "    return X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_with_missing_data(df, threshold=0.95):\n",
    "    \"\"\"\n",
    "    Drops rows with less than a specified percentage of non-null values.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate the minimum number of non-null values required per row\n",
    "    min_non_null = int(threshold * df.shape[1])\n",
    "    \n",
    "    # Filter rows based on the number of non-null values\n",
    "    filtered_df = df.dropna(thresh=min_non_null)\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_dum(X_train, X_val):\n",
    "    # drop_rows_with_missing_data(X_train, threshold=0.90)\n",
    "    # drop_rows_with_missing_data(X_val, threshold=0.90)\n",
    "    drop_description_columns(X_train, X_val)\n",
    "    convert_to_timestamp(X_train, X_val, date_order)\n",
    "    convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "    impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    fill_missing_with_mode(X_train, X_val)\n",
    "    feature_creation_has_Cdate(X_train, X_val)\n",
    "    columns_to_drop = ['C-2 Date','C-3 Date', 'Accident Date', 'Assembly Date']\n",
    "    # X_train = X_train.drop(columns=columns_to_drop)\n",
    "    # X_val = X_val.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "    return X_train, X_val\n",
    "\n",
    "def preprocessing_dum_test(X_test):\n",
    "    convert_to_timestamp_test(X_test, date_order)\n",
    "    convert_to_bool_test(X_test, col_names=BOOLEAN_COLUMNS)\n",
    "    impute_mean_numerical_test(X_test, numerical_columns)\n",
    "    fill_missing_with_mode_test(X_test)\n",
    "    feature_creation_has_Cdate_test(X_test)\n",
    "    return X_test\n",
    "\n",
    "def scaling_encoding(X_train, X_val):\n",
    "    #scaling_minmax(X_train, X_val, col_minmax)\n",
    "    #scaling_standard(X_train, X_val, col_standart)\n",
    "    robust_scaling(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "\n",
    "    return X_train, X_val\n",
    "\n",
    "def scaling_encoding_test(X_test):\n",
    "    #scaling_minmax_test(X_test, col_minmax)\n",
    "    #scaling_standard_test(X_test, col_standart)\n",
    "    X_test= encoding_onehot_test(X_test, low_cardinality_cols)\n",
    "    X_test = encoding_frequency1_test(X_test, high_cardinality_cols)\n",
    "\n",
    "\n",
    "    return X_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.feature_selection import RFE\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Garantir que os índices de X e y estejam alinhados\n",
    "# X = X.reset_index(drop=True)\n",
    "# y = y.reset_index(drop=True)\n",
    "\n",
    "# # Faixa de valores para o parâmetro C\n",
    "# c_range = np.logspace(-3, 2, 10)  # Exemplo de valores de 0.001 a 100\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# mean_f1_scores = []\n",
    "\n",
    "# for c in c_range:\n",
    "#     f1_scores = []\n",
    "#     for train_index, test_index in kf.split(X):\n",
    "#         # Dividir o dataset em treino e validação\n",
    "#         X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "#         y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "#         # Pré-processamento\n",
    "#         X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "#         X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "#         X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "#         y_train,y_val=encoding_label(y_train,y_val)\n",
    "        \n",
    "#         # Seleção de features com RFE\n",
    "#         X_train_selected, selected_features, feature_ranking = feature_selection_rfe(\n",
    "#             X_train, y_train, 10, LogisticRegression()\n",
    "#         )\n",
    "        \n",
    "#         # Treinar o SVM com o valor atual de C\n",
    "#         svm = SVC(C=c, kernel='linear', random_state=42)\n",
    "#         svm.fit(X_train_selected, y_train)\n",
    "        \n",
    "#         # Fazer previsões e calcular o F1 score\n",
    "#         y_pred = svm.predict(X_val[selected_features])\n",
    "#         f1 = f1_score(y_val, y_pred, average='macro')\n",
    "#         f1_scores.append(f1)\n",
    "\n",
    "#     # Armazenar a média dos F1 scores para o valor de C atual\n",
    "#     mean_f1_scores.append(np.mean(f1_scores))\n",
    "\n",
    "# # Determinar o valor ótimo de C\n",
    "# optimal_c = c_range[np.argmax(mean_f1_scores)]\n",
    "# print(f\"The optimal value of C is {optimal_c}.\")\n",
    "\n",
    "\n",
    "# # Treinar o modelo final usando todo o conjunto de dados\n",
    "# X_preprocessed, _ = preprocessing_dum(X, X)\n",
    "# X_scaled, _ = scaling_encoding(X_preprocessed, X_preprocessed)\n",
    "# selector = RFE(estimator=LogisticRegression(), n_features_to_select=10)\n",
    "# X_final = selector.fit_transform(X_scaled, y)\n",
    "# final_svm = SVC(C=optimal_c, kernel='linear', random_state=42)\n",
    "# final_svm.fit(X_final, y)\n",
    "\n",
    "# print(f\"Model trained with optimal C={optimal_c}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Garantir que os índices de X e y estejam alinhados\n",
    "# X = X.reset_index(drop=True)\n",
    "# y = y.reset_index(drop=True)\n",
    "\n",
    "# # Definir o learning rate único\n",
    "# learning_rate = 0.5  # Você pode alterar este valor conforme necessário\n",
    "\n",
    "# # Pré-processamento\n",
    "# print(\"Realizando o pré-processamento...\")\n",
    "# X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "# X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "# X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "# y_train, y_val = encoding_label(y_train, y_val)\n",
    "\n",
    "# # Seleção de features com RFE\n",
    "# print(\"Selecionando features com RFE...\")\n",
    "# X_train_selected, selected_features, feature_ranking = feature_selection_rfe(\n",
    "#     X_train, y_train, 35, LogisticRegression()\n",
    "# )\n",
    "\n",
    "# # Treinamento do modelo\n",
    "# print(\"Treinando o modelo...\")\n",
    "# model = XGBClassifier(learning_rate=learning_rate, use_label_encoder=False, eval_metric='mlogloss')\n",
    "# model.fit(X_train_selected, y_train)\n",
    "\n",
    "# # Avaliação no conjunto de validação\n",
    "# print(\"Avaliando no conjunto de validação...\")\n",
    "# X_val_selected = X_val[selected_features]\n",
    "# y_pred_val = model.predict(X_val_selected)\n",
    "# val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "# val_f1 = f1_score(y_val, y_pred_val, average='weighted')  # Use \"weighted\" para classes desbalanceadas\n",
    "\n",
    "# # Resultados\n",
    "# print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "# print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:425: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:426: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:440: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(mean_value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecionando features com RFECV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:21:43] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:22:07] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:22:35] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:22:58] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:23:21] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:23:43] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:24:05] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:24:26] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:24:48] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:25:08] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:25:29] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:25:50] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:26:11] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:26:34] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:26:55] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:27:14] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:27:38] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:28:03] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:28:21] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:28:40] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:28:59] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:29:17] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:29:36] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:29:54] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:30:12] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:30:30] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:30:47] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:31:05] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:31:21] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:31:38] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:31:55] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:32:11] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:32:27] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:32:43] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo final...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:32:59] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando no conjunto de validação...\n",
      "Validation Accuracy: 0.7800\n",
      "Validation F1 Score: 0.3861\n",
      "Pipeline concluído com sucesso!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Reseta os índices de X e y\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "learning_rate = 0.7  \n",
    "\n",
    "# Preprocessing\n",
    "print(\"Preprocessing...\")\n",
    "X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "X_train, X_val = outliers_iqr(X_train, X_val, X_train.columns)\n",
    "\n",
    "# Preprocessing test data\n",
    "X_test = test_data[~(test_data.drop(columns=['Assembly Date']).isna().all(axis=1) & test_data['Assembly Date'].notna())]\n",
    "X_test = drop_description_columns_Test(X_test)\n",
    "X_test = preprocessing_dum_test(X_test)\n",
    "X_test = scaling_encoding_test(X_test)\n",
    "\n",
    "# Codifica y_train e y_val\n",
    "enc2 = LabelEncoder()\n",
    "enc2.fit(y_train)\n",
    "y_train_encoded = enc2.transform(y_train)\n",
    "y_val_encoded = enc2.transform(y_val)\n",
    "\n",
    "# RFECV com XGBoost\n",
    "print(\"Selecionando features com RFECV...\")\n",
    "\n",
    "model_for_rfe = XGBClassifier(\n",
    "    learning_rate=learning_rate,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")  # Modelo base para RFECV\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=5) \n",
    "\n",
    "rfecv = RFECV(estimator=model_for_rfe, step=1, cv=cv_strategy, scoring='f1_macro', n_jobs=-1)\n",
    "rfecv.fit(X_train, y_train_encoded)\n",
    "# selected_features= [  'Average Weekly Wage', 'Birth Year', 'Number of Dependents', 'Attorney/Representative_False', \n",
    "#                      'Carrier Type_1A. PRIVATE', 'District Name_NYC', 'Gender_F', 'Gender_M', 'Medical Fee Region_IV', 'Carrier Name', \n",
    "#                      'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code','Zip Code']\n",
    "\n",
    "# Seleciona as features com base no RFECV\n",
    "selected_features = X_train.columns[rfecv.support_]\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_val_selected = X_val[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# print(f\"Número de features selecionadas: {len(selected_features)}\")\n",
    "# print(\"Features selecionadas:\", selected_features.tolist())\n",
    "\n",
    "# Treinamento do modelo final com as features selecionadas\n",
    "print(\"Treinando o modelo final...\")\n",
    "model = XGBClassifier(\n",
    "    learning_rate=learning_rate,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_selected, y_train_encoded)\n",
    "\n",
    "# Avaliação no conjunto de validação\n",
    "print(\"Avaliando no conjunto de validação...\")\n",
    "y_pred_val = model.predict(X_val_selected)\n",
    "val_accuracy = accuracy_score(y_val_encoded, y_pred_val)\n",
    "val_f1 = f1_score(y_val_encoded, y_pred_val, average='macro')\n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "# Previsões no conjunto de teste\n",
    "y_pred_test = model.predict(X_test_selected)\n",
    "y_pred_test_decoded = enc2.inverse_transform(y_pred_test)\n",
    "\n",
    "# Formata o arquivo de submissão\n",
    "X_test['Claim Injury Type'] = y_pred_test_decoded\n",
    "sample_submission = X_test[['Claim Injury Type']].set_index(X_test.index)\n",
    "sample_submission.to_csv('submission_xgboost.csv')\n",
    "\n",
    "print(\"Pipeline concluído com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de features selecionadas: 20\n",
      "Features selecionadas: ['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'C-2 Date', 'Number of Dependents', 'Attorney/Representative_False', 'Carrier Type_1A. PRIVATE', 'District Name_NYC', 'Gender_F', 'Gender_M', 'Medical Fee Region_IV', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Número de features selecionadas: {len(selected_features)}\")\n",
    "print(\"Features selecionadas:\", selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  warnings.warn(smsg, UserWarning)\n",
    "Número de features selecionadas: 9\n",
    "Features selecionadas: ['Average Weekly Wage', 'C-2 Date', 'C-3 Date', 'First Hearing Date', 'IME-4 Count', 'Attorney/Representative_False', 'Attorney/Representative_True', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF']\n",
    "Treinando o modelo...\n",
    "Avaliando no conjunto de validação...\n",
    "Validation Accuracy: 0.7765\n",
    "Validation F1 Score: 0.7295\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:425: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:426: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:440: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(mean_value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['ZipCode'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 45\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Feature selection using predefined features\u001b[39;00m\n\u001b[0;32m     41\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccident Date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge at Injury\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAssembly Date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Weekly Wage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBirth Year\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC-2 Date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of Dependents\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttorney/Representative_False\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     42\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCarrier Type_1A. PRIVATE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistrict Name_NYC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender_F\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender_M\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedical Fee Region_IV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCarrier Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     43\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCounty of Injury\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndustry Code\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWCIO Cause of Injury Code\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWCIO Nature of Injury Code\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWCIO Part Of Body Code\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZipCode\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 45\u001b[0m X_train_selected \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_smote\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     46\u001b[0m X_val_selected \u001b[38;5;241m=\u001b[39m X_val[selected_features]\n\u001b[0;32m     47\u001b[0m X_test_selected \u001b[38;5;241m=\u001b[39m X_test[selected_features]\n",
      "File \u001b[1;32mc:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['ZipCode'] not in index\""
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure the indices are reset\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "learning_rate = 0.7  \n",
    "\n",
    "# Preprocessing\n",
    "print(\"Preprocessing...\")\n",
    "X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "X_train, X_val = outliers_iqr(X_train, X_val, X_train.columns)\n",
    "\n",
    "# Preprocess test data\n",
    "X_test = test_data[~(test_data.drop(columns=['Assembly Date']).isna().all(axis=1) & test_data['Assembly Date'].notna())]\n",
    "X_test = drop_description_columns_Test(X_test)\n",
    "X_test = preprocessing_dum_test(X_test)\n",
    "X_test = scaling_encoding_test(X_test)\n",
    "\n",
    "# Encode labels\n",
    "enc2 = LabelEncoder()\n",
    "enc2.fit(y_train)\n",
    "\n",
    "# Encode y_train and y_val\n",
    "y_train_encoded = enc2.transform(y_train)\n",
    "y_val_encoded = enc2.transform(y_val)\n",
    "\n",
    "# Apply SMOTE on the training data\n",
    "print(\"Applying SMOTE...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train_encoded)\n",
    "\n",
    "# Feature selection using predefined features\n",
    "selected_features = ['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'C-2 Date', 'Number of Dependents', 'Attorney/Representative_False', \n",
    "                     'Carrier Type_1A. PRIVATE', 'District Name_NYC', 'Gender_F', 'Gender_M', 'Medical Fee Region_IV', 'Carrier Name', \n",
    "                     'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code','ZipCode']\n",
    "\n",
    "X_train_selected = X_train_smote[selected_features]\n",
    "X_val_selected = X_val[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Train the XGBoost model\n",
    "print(\"Training the XGBoost model...\")\n",
    "model = XGBClassifier(learning_rate=learning_rate, use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train_selected, y_train_smote)\n",
    "\n",
    "# Evaluate on validation data\n",
    "print(\"Evaluating on the validation set...\")\n",
    "y_pred_val = model.predict(X_val_selected)\n",
    "val_accuracy = accuracy_score(y_val_encoded, y_pred_val)\n",
    "val_f1 = f1_score(y_val_encoded, y_pred_val, average='macro')\n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = model.predict(X_test_selected)\n",
    "y_pred_test_decoded = enc2.inverse_transform(y_pred_test)\n",
    "\n",
    "# Format the submission file\n",
    "X_test['Claim Injury Type'] = y_pred_test_decoded\n",
    "sample_submission = X_test[['Claim Injury Type']].set_index(X_test.index)\n",
    "sample_submission.to_csv('submission_xgboost_smote.csv')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'xgboost_model_smote.pkl')\n",
    "\n",
    "print(\"XGBoost model with SMOTE training and prediction completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to Evaluate XGBoost for different Learning Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:425: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:426: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:440: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(mean_value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features RFECV...\n",
      "Training model with learning rate: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:15:38] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Accuracy for lr=0.2: 0.7528\n",
      "Validation F1 Score for lr=0.2: 0.2992\n",
      "Saved predictions to submission_xgboost_lr_0.2.csv\n",
      "Training model with learning rate: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:15:50] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Accuracy for lr=0.4: 0.7522\n",
      "Validation F1 Score for lr=0.4: 0.3000\n",
      "Saved predictions to submission_xgboost_lr_0.4.csv\n",
      "Training model with learning rate: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:16:03] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Accuracy for lr=0.5: 0.7522\n",
      "Validation F1 Score for lr=0.5: 0.3002\n",
      "Saved predictions to submission_xgboost_lr_0.5.csv\n",
      "Training model with learning rate: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:16:17] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Accuracy for lr=0.7: 0.7518\n",
      "Validation F1 Score for lr=0.7: 0.3011\n",
      "Saved predictions to submission_xgboost_lr_0.7.csv\n",
      "Training model with learning rate: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:16:31] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Accuracy for lr=0.8: 0.7510\n",
      "Validation F1 Score for lr=0.8: 0.3008\n",
      "Saved predictions to submission_xgboost_lr_0.8.csv\n",
      "Learning Rate Evaluation Results:\n",
      "   Learning Rate  Validation Accuracy  Validation F1 Score\n",
      "0            0.2             0.752757             0.299214\n",
      "1            0.4             0.752217             0.300004\n",
      "2            0.5             0.752208             0.300182\n",
      "3            0.7             0.751764             0.301075\n",
      "4            0.8             0.750997             0.300825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Define the learning rates to evaluate\n",
    "learning_rates = [ 0.2, 0.4, 0.5, 0.7, 0.8]\n",
    "\n",
    "# Dictionary to store results for each learning rate\n",
    "results = []\n",
    "\n",
    "# preprocessing\n",
    "print(\"preprocessing...\")\n",
    "X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "X_train,X_val=outliers_iqr(X_train,X_val,X_train.columns)\n",
    "\n",
    "#preprocessing test data\n",
    "X_test = test_data[~(test_data.drop(columns=['Assembly Date']).isna().all(axis=1) & test_data['Assembly Date'].notna())] \n",
    "X_test= drop_description_columns_Test(X_test)\n",
    "X_test= preprocessing_dum_test(X_test)\n",
    "X_test = scaling_encoding_test(X_test)\n",
    "\n",
    "enc2 = LabelEncoder()\n",
    "enc2.fit(y_train)\n",
    "\n",
    "# Codifica os valores de y_train e y_val\n",
    "y_train_encoded = enc2.transform(y_train)\n",
    "y_val_encoded = enc2.transform(y_val)\n",
    "\n",
    "# RFECV\n",
    "print(\"Selecting features RFECV...\")\n",
    "selected_features = ['Average Weekly Wage', 'C-2 Date', 'C-3 Date', 'First Hearing Date', \n",
    "                    'IME-4 Count', 'Attorney/Representative_False', 'Attorney/Representative_True', \n",
    "                    'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF']\n",
    "\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_val_selected = X_val[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Loop through each learning rate\n",
    "for lr in learning_rates:\n",
    "    print(f\"Training model with learning rate: {lr}\")\n",
    "    \n",
    "    # Train the model\n",
    "    model = XGBClassifier(learning_rate=lr, use_label_encoder=False, eval_metric='mlogloss')\n",
    "    model.fit(X_train_selected, y_train_encoded)\n",
    "    \n",
    "    # Evaluate on validation data\n",
    "    print(\"Evaluating on validation set...\")\n",
    "    y_pred_val = model.predict(X_val_selected)\n",
    "    val_accuracy = accuracy_score(y_val_encoded, y_pred_val)\n",
    "    val_f1 = f1_score(y_val_encoded, y_pred_val, average='macro')  \n",
    "    \n",
    "    print(f\"Validation Accuracy for lr={lr}: {val_accuracy:.4f}\")\n",
    "    print(f\"Validation F1 Score for lr={lr}: {val_f1:.4f}\")\n",
    "    \n",
    "    \n",
    "    # Store the results\n",
    "    results.append({'Learning Rate': lr, 'Validation Accuracy': val_accuracy, 'Validation F1 Score': val_f1})\n",
    "    \n",
    "    # Predict on test data for the current model\n",
    "    y_pred_test = model.predict(X_test_selected)\n",
    "    y_pred_test_decoded = enc2.inverse_transform(y_pred_test)\n",
    "    \n",
    "    # Format the submission file for the current learning rate\n",
    "    X_test['Claim Injury Type'] = y_pred_test_decoded\n",
    "    sample_submission = X_test[['Claim Injury Type']].set_index(X_test.index)\n",
    "    submission_filename = f'submission_xgboost_lr_{lr}.csv'\n",
    "    sample_submission.to_csv(submission_filename)\n",
    "    print(f\"Saved predictions to {submission_filename}\")\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "print(\"Learning Rate Evaluation Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('learning_rate_evaluation_results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
