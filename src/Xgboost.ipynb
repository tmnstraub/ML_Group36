{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.svm import SVC\n",
    "from Preprocessing_functions import *\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inesm\\AppData\\Local\\Temp\\ipykernel_2972\\3470921380.py:1: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n",
    "test_data = pd.read_csv('test_data.csv', index_col='Claim Identifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and validation sets\n",
    "train_data = train_data[~(train_data.drop(columns=['Assembly Date']).isna().all(axis=1) & train_data['Assembly Date'].notna())] \n",
    "X = train_data.drop(columns=['Claim Injury Type', 'WCB Decision', 'Agreement Reached'])\n",
    "y = train_data['Claim Injury Type']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_COLUMNS = ['Industry Code', 'WCIO Cause of Injury Code',\n",
    "       'WCIO Nature of Injury Code', 'WCIO Part Of Body Code']\n",
    "\n",
    "DESCRIPTION_COLUMNS = ['WCIO Cause of Injury Description','WCIO Nature of Injury Description','WCIO Part Of Body Description','Industry Code Description']\n",
    "\n",
    "BOOLEAN_COLUMNS = ['Alternative Dispute Resolution', 'Attorney/Representative','COVID-19 Indicator']\n",
    "\n",
    "date_order = ['Accident Date', 'C-2 Date','C-3 Date','Assembly Date', 'First Hearing Date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    'Accident Date', \n",
    "    'Age at Injury', \n",
    "    'Assembly Date', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year', \n",
    "    'C-2 Date', \n",
    "    'C-3 Date', \n",
    "    'First Hearing Date', \n",
    "    'IME-4 Count', \n",
    "]\n",
    "\n",
    "categorical_features = ['Alternative Dispute Resolution',\n",
    " 'Attorney/Representative',\n",
    " 'Carrier Name',\n",
    " 'Carrier Type',\n",
    " 'County of Injury',\n",
    " 'COVID-19 Indicator',\n",
    " 'District Name',\n",
    " 'Gender',\n",
    " 'Industry Code',\n",
    " 'Medical Fee Region',\n",
    " 'WCIO Cause of Injury Code',\n",
    " 'WCIO Nature of Injury Code',\n",
    " 'WCIO Part Of Body Code',\n",
    " 'Zip Code']\n",
    "\n",
    "col_minmax = ['Age at Injury',\n",
    "               'Birth Year', \n",
    "               'Number of Dependents']\n",
    "\n",
    "col_standart = ['Accident Date',\n",
    "                'Assembly Date',\n",
    "                'Average Weekly Wage',\n",
    "                ]\n",
    "\n",
    "low_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() < 10]\n",
    "high_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() > 10]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carrier Name',\n",
       " 'County of Injury',\n",
       " 'Industry Code',\n",
       " 'WCIO Cause of Injury Code',\n",
       " 'WCIO Nature of Injury Code',\n",
       " 'WCIO Part Of Body Code',\n",
       " 'Zip Code']"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_cardinality_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
    "X_val[categorical_features] = X_val[categorical_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_description_columns(X_train, X_val):\n",
    "    \"\"\"\n",
    "    Drop all columns in X_train and X_val that contain the word 'description' in their names (case-insensitive).\n",
    "    \"\"\"\n",
    "    description_columns = X_train.columns[X_train.columns.str.contains('description', case=False, na=False)]\n",
    "    \n",
    "\n",
    "    X_train = X_train.drop(description_columns, axis=1)\n",
    "    X_val = X_val.drop(description_columns, axis=1)\n",
    "    \n",
    "    return X_train, X_val\n",
    "\n",
    "X_train ,X_val = drop_description_columns(X_train, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_description_columns_Test(X_test):\n",
    "    \"\"\"\n",
    "    Drop all columns in X_train and X_val that contain the word 'description' in their names (case-insensitive).\n",
    "    \"\"\"\n",
    "    description_columns = X_test.columns[X_test.columns.str.contains('description', case=False, na=False)]\n",
    "    \n",
    "\n",
    "    X_test = X_test.drop(description_columns, axis=1)\n",
    "    \n",
    "    return X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_dum(X_train, X_val):\n",
    "    drop_description_columns(X_train, X_val)\n",
    "    convert_to_timestamp(X_train, X_val, date_order)\n",
    "    convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "    impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    fill_missing_with_mode(X_train, X_val)\n",
    "    feature_creation_has_Cdate(X_train, X_val)\n",
    "    # columns_to_drop = ['C-2 Date', 'C-3 Date', 'First Hearing Date']\n",
    "    # X_train = X_train.drop(columns=columns_to_drop)\n",
    "    # X_val = X_val.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "    return X_train, X_val\n",
    "\n",
    "def preprocessing_dum_test(X_test):\n",
    "    convert_to_timestamp_test(X_test, date_order)\n",
    "    convert_to_bool_test(X_test, col_names=BOOLEAN_COLUMNS)\n",
    "    impute_mean_numerical_test(X_test, numerical_columns)\n",
    "    fill_missing_with_mode_test(X_test)\n",
    "    feature_creation_has_Cdate_test(X_test)\n",
    "    return X_test\n",
    "\n",
    "def scaling_encoding(X_train, X_val):\n",
    "    #scaling_minmax(X_train, X_val, col_minmax)\n",
    "    #scaling_standard(X_train, X_val, col_standart)\n",
    "    robust_scaling(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "\n",
    "    return X_train, X_val\n",
    "\n",
    "def scaling_encoding_test(X_test):\n",
    "    #scaling_minmax_test(X_test, col_minmax)\n",
    "    #scaling_standard_test(X_test, col_standart)\n",
    "    X_test= encoding_onehot_test(X_test, low_cardinality_cols)\n",
    "    X_test = encoding_frequency1_test(X_test, high_cardinality_cols)\n",
    "\n",
    "\n",
    "    return X_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.feature_selection import RFE\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Garantir que os índices de X e y estejam alinhados\n",
    "# X = X.reset_index(drop=True)\n",
    "# y = y.reset_index(drop=True)\n",
    "\n",
    "# # Faixa de valores para o parâmetro C\n",
    "# c_range = np.logspace(-3, 2, 10)  # Exemplo de valores de 0.001 a 100\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# mean_f1_scores = []\n",
    "\n",
    "# for c in c_range:\n",
    "#     f1_scores = []\n",
    "#     for train_index, test_index in kf.split(X):\n",
    "#         # Dividir o dataset em treino e validação\n",
    "#         X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "#         y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "#         # Pré-processamento\n",
    "#         X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "#         X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "#         X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "#         y_train,y_val=encoding_label(y_train,y_val)\n",
    "        \n",
    "#         # Seleção de features com RFE\n",
    "#         X_train_selected, selected_features, feature_ranking = feature_selection_rfe(\n",
    "#             X_train, y_train, 10, LogisticRegression()\n",
    "#         )\n",
    "        \n",
    "#         # Treinar o SVM com o valor atual de C\n",
    "#         svm = SVC(C=c, kernel='linear', random_state=42)\n",
    "#         svm.fit(X_train_selected, y_train)\n",
    "        \n",
    "#         # Fazer previsões e calcular o F1 score\n",
    "#         y_pred = svm.predict(X_val[selected_features])\n",
    "#         f1 = f1_score(y_val, y_pred, average='macro')\n",
    "#         f1_scores.append(f1)\n",
    "\n",
    "#     # Armazenar a média dos F1 scores para o valor de C atual\n",
    "#     mean_f1_scores.append(np.mean(f1_scores))\n",
    "\n",
    "# # Determinar o valor ótimo de C\n",
    "# optimal_c = c_range[np.argmax(mean_f1_scores)]\n",
    "# print(f\"The optimal value of C is {optimal_c}.\")\n",
    "\n",
    "# # Plotar os F1 scores médios para cada valor de C\n",
    "# plt.plot(c_range, mean_f1_scores)\n",
    "# plt.xscale('log')  # Escala logarítmica para melhor visualização\n",
    "# plt.xlabel('C (Regularization Parameter)')\n",
    "# plt.ylabel('Mean F1 Score')\n",
    "# plt.title('Optimal C Selection using K-Fold Cross-Validation')\n",
    "# plt.show()\n",
    "\n",
    "# # Treinar o modelo final usando todo o conjunto de dados\n",
    "# X_preprocessed, _ = preprocessing_dum(X, X)\n",
    "# X_scaled, _ = scaling_encoding(X_preprocessed, X_preprocessed)\n",
    "# selector = RFE(estimator=LogisticRegression(), n_features_to_select=10)\n",
    "# X_final = selector.fit_transform(X_scaled, y)\n",
    "# final_svm = SVC(C=optimal_c, kernel='linear', random_state=42)\n",
    "# final_svm.fit(X_final, y)\n",
    "\n",
    "# print(f\"Model trained with optimal C={optimal_c}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Garantir que os índices de X e y estejam alinhados\n",
    "# X = X.reset_index(drop=True)\n",
    "# y = y.reset_index(drop=True)\n",
    "\n",
    "# # Definir o learning rate único\n",
    "# learning_rate = 0.5  # Você pode alterar este valor conforme necessário\n",
    "\n",
    "# # Pré-processamento\n",
    "# print(\"Realizando o pré-processamento...\")\n",
    "# X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "# X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "# X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "# y_train, y_val = encoding_label(y_train, y_val)\n",
    "\n",
    "# # Seleção de features com RFE\n",
    "# print(\"Selecionando features com RFE...\")\n",
    "# X_train_selected, selected_features, feature_ranking = feature_selection_rfe(\n",
    "#     X_train, y_train, 35, LogisticRegression()\n",
    "# )\n",
    "\n",
    "# # Treinamento do modelo\n",
    "# print(\"Treinando o modelo...\")\n",
    "# model = XGBClassifier(learning_rate=learning_rate, use_label_encoder=False, eval_metric='mlogloss')\n",
    "# model.fit(X_train_selected, y_train)\n",
    "\n",
    "# # Avaliação no conjunto de validação\n",
    "# print(\"Avaliando no conjunto de validação...\")\n",
    "# X_val_selected = X_val[selected_features]\n",
    "# y_pred_val = model.predict(X_val_selected)\n",
    "# val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "# val_f1 = f1_score(y_val, y_pred_val, average='weighted')  # Use \"weighted\" para classes desbalanceadas\n",
    "\n",
    "# # Resultados\n",
    "# print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "# print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:425: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:426: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:440: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(mean_value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features RFECV...\n",
      "Treinando o modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:54:25] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando no conjunto de validação...\n",
      "Validation Accuracy: 0.7522\n",
      "Validation F1 Score: 0.3002\n",
      "Classes ajustadas no encoder: ['1. CANCELLED' '2. NON-COMP' '3. MED ONLY' '4. TEMPORARY'\n",
      " '5. PPD SCH LOSS' '6. PPD NSL' '7. PTD' '8. DEATH']\n",
      "Valores únicos previstos no teste: [1 2 3 4]\n",
      "Valores decodificados: ['3. MED ONLY' '3. MED ONLY' '2. NON-COMP' '2. NON-COMP' '2. NON-COMP'\n",
      " '2. NON-COMP' '4. TEMPORARY' '2. NON-COMP' '2. NON-COMP'\n",
      " '5. PPD SCH LOSS']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "learning_rate = 0.5  \n",
    "\n",
    "# preprocessing\n",
    "print(\"preprocessing...\")\n",
    "X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "X_train,X_val=outliers_iqr(X_train,X_val,X_train.columns)\n",
    "\n",
    "#preprocessing test data\n",
    "X_test = test_data[~(test_data.drop(columns=['Assembly Date']).isna().all(axis=1) & test_data['Assembly Date'].notna())] \n",
    "X_test= drop_description_columns_Test(X_test)\n",
    "X_test= preprocessing_dum_test(X_test)\n",
    "X_test = scaling_encoding_test(X_test)\n",
    "\n",
    "enc2 = LabelEncoder()\n",
    "enc2.fit(y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Codifica os valores de y_train e y_val\n",
    "y_train_encoded = enc2.transform(y_train)\n",
    "y_val_encoded = enc2.transform(y_val)\n",
    "\n",
    "# RFECV\n",
    "print(\"Selecting features RFECV...\")\n",
    "# model_for_rfe = LogisticRegression(max_iter=1000)  # Modelo base para RFECV\n",
    "# cv_strategy = StratifiedKFold(n_splits=5)  # Estratégia de validação cruzada\n",
    "\n",
    "# rfecv = RFECV(estimator=model_for_rfe, step=1, cv=cv_strategy, scoring='accuracy', n_jobs=-1)\n",
    "# rfecv.fit(X_train, y_train)\n",
    "\n",
    "#selected_features = X_train.columns[rfecv.support_]\n",
    "selected_features = ['Average Weekly Wage', 'C-2 Date', 'C-3 Date', 'First Hearing Date', \n",
    "                     'IME-4 Count', 'Attorney/Representative_False', 'Attorney/Representative_True', \n",
    "                     'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF']\n",
    "\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_val_selected = X_val[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "#print(f\"Número de features selecionadas: {len(selected_features)}\")\n",
    "#print(\"Features selecionadas:\", selected_features.tolist())\n",
    "\n",
    "# Treinamento do modelo com as features selecionadas\n",
    "print(\"Treinando o modelo...\")\n",
    "model = XGBClassifier(learning_rate=learning_rate, use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train_selected, y_train_encoded)\n",
    "\n",
    "# Avaliação no conjunto de validação\n",
    "print(\"Avaliando no conjunto de validação...\")\n",
    "y_pred_val = model.predict(X_val_selected)\n",
    "val_accuracy = accuracy_score(y_val_encoded, y_pred_val)\n",
    "val_f1 = f1_score(y_val_encoded, y_pred_val, average='macro')  \n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "y_pred_test = model.predict(X_test_selected)\n",
    "# Verificar as classes ajustadas\n",
    "print(\"Classes ajustadas no encoder:\", enc2.classes_)\n",
    "\n",
    "# Garantir que os valores previstos estão dentro do domínio das classes ajustadas\n",
    "print(\"Valores únicos previstos no teste:\", np.unique(y_pred_test))\n",
    "\n",
    "# Decodificar os valores previstos\n",
    "try:\n",
    "    y_pred_test_decoded = enc2.inverse_transform(y_pred_test)\n",
    "    print(\"Valores decodificados:\", y_pred_test_decoded[:10])  # Exibir os primeiros 10 valores\n",
    "except ValueError as e:\n",
    "    print(f\"Erro durante a decodificação: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_f1 = f1_score(y_val, y_pred_val, average='macro')  \n",
    "# val_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  warnings.warn(smsg, UserWarning)\n",
    "Número de features selecionadas: 9\n",
    "Features selecionadas: ['Average Weekly Wage', 'C-2 Date', 'C-3 Date', 'First Hearing Date', 'IME-4 Count', 'Attorney/Representative_False', 'Attorney/Representative_True', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF']\n",
    "Treinando o modelo...\n",
    "Avaliando no conjunto de validação...\n",
    "Validation Accuracy: 0.7765\n",
    "Validation F1 Score: 0.7295\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3. MED ONLY', '3. MED ONLY', '2. NON-COMP', ..., '2. NON-COMP',\n",
       "       '2. NON-COMP', '2. NON-COMP'], dtype=object)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = enc2.inverse_transform(y_pred_test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "## formating the submission file\n",
    "X_test['Claim Injury Type'] = test\n",
    "sample_submission = X_test[['Claim Injury Type']].set_index(X_test.index)\n",
    "sample_submission.to_csv('submission_xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.feature_selection import RFECV\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # Preprocessing\n",
    "# print(\"Preprocessing...\")\n",
    "# X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "# X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "# X_train, X_val = outliers_iqr(X_train, X_val, X_train.columns)\n",
    "# y_train, y_val = encoding_label(y_train, y_val)\n",
    "\n",
    "# # Preprocessing test data\n",
    "# X_test = test_data[~(test_data.drop(columns=['Assembly Date']).isna().all(axis=1) & test_data['Assembly Date'].notna())]\n",
    "# X_test = drop_description_columns_Test(X_test)\n",
    "# X_test = preprocessing_dum_test(X_test)\n",
    "# X_test = scaling_encoding_test(X_test)\n",
    "\n",
    "# enc2 = LabelEncoder()\n",
    "# enc2.fit(y_train)\n",
    "\n",
    "# # Seleção de features (substituindo a execução real para economizar tempo)\n",
    "# print(\"Selecionando features...\")\n",
    "# selected_features = ['Average Weekly Wage', 'C-2 Date', 'C-3 Date', 'First Hearing Date',\n",
    "#                      'IME-4 Count', 'Attorney/Representative_False', 'Attorney/Representative_True',\n",
    "#                      'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF']\n",
    "\n",
    "# X_train_selected = X_train[selected_features]\n",
    "# X_val_selected = X_val[selected_features]\n",
    "# X_test_selected = X_test[selected_features]\n",
    "\n",
    "# # Treinamento com CatBoost\n",
    "# print(\"Treinando o modelo com CatBoost...\")\n",
    "# model = CatBoostClassifier(\n",
    "#     learning_rate=0.5,\n",
    "#     iterations=500,\n",
    "#     depth=6,\n",
    "#     eval_metric='TotalF1',\n",
    "#     verbose=100,  # Exibe progresso a cada 100 iterações\n",
    "#     random_seed=42\n",
    "# )\n",
    "\n",
    "# model.fit(\n",
    "#     X_train_selected,\n",
    "#     y_train,\n",
    "#     eval_set=(X_val_selected, y_val),\n",
    "#     use_best_model=True\n",
    "# )\n",
    "\n",
    "# # Avaliação no conjunto de validação\n",
    "# print(\"Avaliando no conjunto de validação...\")\n",
    "# y_pred_val = model.predict(X_val_selected)\n",
    "# val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "# val_f1 = f1_score(y_val, y_pred_val, average='macro')\n",
    "\n",
    "# print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "# print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "# # Predição no conjunto de teste\n",
    "# y_pred_test = model.predict(X_test_selected)\n",
    "\n",
    "# # Resultados\n",
    "# print(\"Predições no conjunto de teste feitas!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
