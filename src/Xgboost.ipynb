{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.svm import SVC\n",
    "from Preprocessing_functions import *\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inesm\\AppData\\Local\\Temp\\ipykernel_7292\\3470921380.py:1: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n",
    "test_data = pd.read_csv('test_data.csv', index_col='Claim Identifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and validation sets\n",
    "train_data = train_data[~(train_data.drop(columns=['Assembly Date']).isna().all(axis=1) & train_data['Assembly Date'].notna())] \n",
    "X = train_data.drop(columns=['Claim Injury Type', 'WCB Decision', 'Agreement Reached'])\n",
    "y = train_data['Claim Injury Type']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_COLUMNS = ['Industry Code', 'WCIO Cause of Injury Code',\n",
    "       'WCIO Nature of Injury Code', 'WCIO Part Of Body Code']\n",
    "\n",
    "DESCRIPTION_COLUMNS = ['WCIO Cause of Injury Description','WCIO Nature of Injury Description','WCIO Part Of Body Description','Industry Code Description']\n",
    "\n",
    "BOOLEAN_COLUMNS = ['Alternative Dispute Resolution', 'Attorney/Representative','COVID-19 Indicator']\n",
    "\n",
    "date_order = ['Accident Date', 'C-2 Date','C-3 Date','Assembly Date', 'First Hearing Date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    'Accident Date', \n",
    "    'Age at Injury', \n",
    "    'Assembly Date', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year', \n",
    "    'C-2 Date', \n",
    "    'C-3 Date', \n",
    "    'First Hearing Date', \n",
    "    'IME-4 Count', \n",
    "]\n",
    "\n",
    "categorical_features = ['Alternative Dispute Resolution',\n",
    " 'Attorney/Representative',\n",
    " 'Carrier Name',\n",
    " 'Carrier Type',\n",
    " 'County of Injury',\n",
    " 'COVID-19 Indicator',\n",
    " 'District Name',\n",
    " 'Gender',\n",
    " 'Industry Code',\n",
    " 'Medical Fee Region',\n",
    " 'WCIO Cause of Injury Code',\n",
    " 'WCIO Nature of Injury Code',\n",
    " 'WCIO Part Of Body Code',\n",
    " 'Zip Code']\n",
    "\n",
    "col_minmax = ['Age at Injury',\n",
    "               'Birth Year', \n",
    "               'Number of Dependents']\n",
    "\n",
    "col_standart = ['Accident Date',\n",
    "                'Assembly Date',\n",
    "                'Average Weekly Wage',\n",
    "                ]\n",
    "\n",
    "low_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() < 10]\n",
    "high_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() > 10]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carrier Name',\n",
       " 'County of Injury',\n",
       " 'Industry Code',\n",
       " 'WCIO Cause of Injury Code',\n",
       " 'WCIO Nature of Injury Code',\n",
       " 'WCIO Part Of Body Code',\n",
       " 'Zip Code']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_cardinality_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
    "X_val[categorical_features] = X_val[categorical_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_description_columns(X_train, X_val):\n",
    "    \"\"\"\n",
    "    Drop all columns in X_train and X_val that contain the word 'description' in their names (case-insensitive).\n",
    "    \"\"\"\n",
    "    description_columns = X_train.columns[X_train.columns.str.contains('description', case=False, na=False)]\n",
    "    \n",
    "\n",
    "    X_train = X_train.drop(description_columns, axis=1)\n",
    "    X_val = X_val.drop(description_columns, axis=1)\n",
    "    \n",
    "    return X_train, X_val\n",
    "\n",
    "X_train ,X_val = drop_description_columns(X_train, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_description_columns_Test(X_test):\n",
    "    \"\"\"\n",
    "    Drop all columns in X_train and X_val that contain the word 'description' in their names (case-insensitive).\n",
    "    \"\"\"\n",
    "    description_columns = X_test.columns[X_test.columns.str.contains('description', case=False, na=False)]\n",
    "    \n",
    "\n",
    "    X_test = X_test.drop(description_columns, axis=1)\n",
    "    \n",
    "    return X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_with_missing_data(df, threshold=0.95):\n",
    "    \"\"\"\n",
    "    Drops rows with less than a specified percentage of non-null values.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate the minimum number of non-null values required per row\n",
    "    min_non_null = int(threshold * df.shape[1])\n",
    "    \n",
    "    # Filter rows based on the number of non-null values\n",
    "    filtered_df = df.dropna(thresh=min_non_null)\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_dum(X_train, X_val):\n",
    "    # drop_rows_with_missing_data(X_train, threshold=0.90)\n",
    "    # drop_rows_with_missing_data(X_val, threshold=0.90)\n",
    "    drop_description_columns(X_train, X_val)\n",
    "    convert_to_timestamp(X_train, X_val, date_order)\n",
    "    convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "    impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    fill_missing_with_mode(X_train, X_val)\n",
    "    feature_creation_has_Cdate(X_train, X_val)\n",
    "    # columns_to_drop = ['C-2 Date', 'C-3 Date', 'First Hearing Date']\n",
    "    # X_train = X_train.drop(columns=columns_to_drop)\n",
    "    # X_val = X_val.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "    return X_train, X_val\n",
    "\n",
    "def preprocessing_dum_test(X_test):\n",
    "    convert_to_timestamp_test(X_test, date_order)\n",
    "    convert_to_bool_test(X_test, col_names=BOOLEAN_COLUMNS)\n",
    "    impute_mean_numerical_test(X_test, numerical_columns)\n",
    "    fill_missing_with_mode_test(X_test)\n",
    "    feature_creation_has_Cdate_test(X_test)\n",
    "    return X_test\n",
    "\n",
    "def scaling_encoding(X_train, X_val):\n",
    "    #scaling_minmax(X_train, X_val, col_minmax)\n",
    "    #scaling_standard(X_train, X_val, col_standart)\n",
    "    robust_scaling(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "\n",
    "    return X_train, X_val\n",
    "\n",
    "def scaling_encoding_test(X_test):\n",
    "    #scaling_minmax_test(X_test, col_minmax)\n",
    "    #scaling_standard_test(X_test, col_standart)\n",
    "    X_test= encoding_onehot_test(X_test, low_cardinality_cols)\n",
    "    X_test = encoding_frequency1_test(X_test, high_cardinality_cols)\n",
    "\n",
    "\n",
    "    return X_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.feature_selection import RFE\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Garantir que os índices de X e y estejam alinhados\n",
    "# X = X.reset_index(drop=True)\n",
    "# y = y.reset_index(drop=True)\n",
    "\n",
    "# # Faixa de valores para o parâmetro C\n",
    "# c_range = np.logspace(-3, 2, 10)  # Exemplo de valores de 0.001 a 100\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# mean_f1_scores = []\n",
    "\n",
    "# for c in c_range:\n",
    "#     f1_scores = []\n",
    "#     for train_index, test_index in kf.split(X):\n",
    "#         # Dividir o dataset em treino e validação\n",
    "#         X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "#         y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "#         # Pré-processamento\n",
    "#         X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "#         X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "#         X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "#         y_train,y_val=encoding_label(y_train,y_val)\n",
    "        \n",
    "#         # Seleção de features com RFE\n",
    "#         X_train_selected, selected_features, feature_ranking = feature_selection_rfe(\n",
    "#             X_train, y_train, 10, LogisticRegression()\n",
    "#         )\n",
    "        \n",
    "#         # Treinar o SVM com o valor atual de C\n",
    "#         svm = SVC(C=c, kernel='linear', random_state=42)\n",
    "#         svm.fit(X_train_selected, y_train)\n",
    "        \n",
    "#         # Fazer previsões e calcular o F1 score\n",
    "#         y_pred = svm.predict(X_val[selected_features])\n",
    "#         f1 = f1_score(y_val, y_pred, average='macro')\n",
    "#         f1_scores.append(f1)\n",
    "\n",
    "#     # Armazenar a média dos F1 scores para o valor de C atual\n",
    "#     mean_f1_scores.append(np.mean(f1_scores))\n",
    "\n",
    "# # Determinar o valor ótimo de C\n",
    "# optimal_c = c_range[np.argmax(mean_f1_scores)]\n",
    "# print(f\"The optimal value of C is {optimal_c}.\")\n",
    "\n",
    "\n",
    "# # Treinar o modelo final usando todo o conjunto de dados\n",
    "# X_preprocessed, _ = preprocessing_dum(X, X)\n",
    "# X_scaled, _ = scaling_encoding(X_preprocessed, X_preprocessed)\n",
    "# selector = RFE(estimator=LogisticRegression(), n_features_to_select=10)\n",
    "# X_final = selector.fit_transform(X_scaled, y)\n",
    "# final_svm = SVC(C=optimal_c, kernel='linear', random_state=42)\n",
    "# final_svm.fit(X_final, y)\n",
    "\n",
    "# print(f\"Model trained with optimal C={optimal_c}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Garantir que os índices de X e y estejam alinhados\n",
    "# X = X.reset_index(drop=True)\n",
    "# y = y.reset_index(drop=True)\n",
    "\n",
    "# # Definir o learning rate único\n",
    "# learning_rate = 0.5  # Você pode alterar este valor conforme necessário\n",
    "\n",
    "# # Pré-processamento\n",
    "# print(\"Realizando o pré-processamento...\")\n",
    "# X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "# X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "# X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "# y_train, y_val = encoding_label(y_train, y_val)\n",
    "\n",
    "# # Seleção de features com RFE\n",
    "# print(\"Selecionando features com RFE...\")\n",
    "# X_train_selected, selected_features, feature_ranking = feature_selection_rfe(\n",
    "#     X_train, y_train, 35, LogisticRegression()\n",
    "# )\n",
    "\n",
    "# # Treinamento do modelo\n",
    "# print(\"Treinando o modelo...\")\n",
    "# model = XGBClassifier(learning_rate=learning_rate, use_label_encoder=False, eval_metric='mlogloss')\n",
    "# model.fit(X_train_selected, y_train)\n",
    "\n",
    "# # Avaliação no conjunto de validação\n",
    "# print(\"Avaliando no conjunto de validação...\")\n",
    "# X_val_selected = X_val[selected_features]\n",
    "# y_pred_val = model.predict(X_val_selected)\n",
    "# val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "# val_f1 = f1_score(y_val, y_pred_val, average='weighted')  # Use \"weighted\" para classes desbalanceadas\n",
    "\n",
    "# # Resultados\n",
    "# print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "# print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:425: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:426: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:440: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(mean_value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features RFECV...\n",
      "Treinando o modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:28:15] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando no conjunto de validação...\n",
      "Validation Accuracy: 0.7518\n",
      "Validation F1 Score: 0.3011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgboost_model.pkl']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "learning_rate = 0.7  \n",
    "\n",
    "# preprocessing\n",
    "print(\"preprocessing...\")\n",
    "X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "X_train,X_val=outliers_iqr(X_train,X_val,X_train.columns)\n",
    "\n",
    "#preprocessing test data\n",
    "X_test = test_data[~(test_data.drop(columns=['Assembly Date']).isna().all(axis=1) & test_data['Assembly Date'].notna())] \n",
    "X_test= drop_description_columns_Test(X_test)\n",
    "X_test= preprocessing_dum_test(X_test)\n",
    "X_test = scaling_encoding_test(X_test)\n",
    "\n",
    "enc2 = LabelEncoder()\n",
    "enc2.fit(y_train)\n",
    "\n",
    "# Codifica os valores de y_train e y_val\n",
    "y_train_encoded = enc2.transform(y_train)\n",
    "y_val_encoded = enc2.transform(y_val)\n",
    "\n",
    "# RFECV\n",
    "print(\"Selecting features RFECV...\")\n",
    "# model_for_rfe = LogisticRegression(max_iter=1000)  # Modelo base para RFECV\n",
    "# cv_strategy = StratifiedKFold(n_splits=5)  # Estratégia de validação cruzada\n",
    "\n",
    "# rfecv = RFECV(estimator=model_for_rfe, step=1, cv=cv_strategy, scoring='accuracy', n_jobs=-1)\n",
    "# rfecv.fit(X_train, y_train)\n",
    "\n",
    "#selected_features = X_train.columns[rfecv.support_]\n",
    "selected_features = ['Average Weekly Wage', 'C-2 Date', 'C-3 Date', 'First Hearing Date', \n",
    "                     'IME-4 Count', 'Attorney/Representative_False', 'Attorney/Representative_True', \n",
    "                     'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF']\n",
    "\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_val_selected = X_val[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "#print(f\"Número de features selecionadas: {len(selected_features)}\")\n",
    "#print(\"Features selecionadas:\", selected_features.tolist())\n",
    "\n",
    "# Treinamento do modelo com as features selecionadas\n",
    "print(\"Treinando o modelo...\")\n",
    "model = XGBClassifier(learning_rate=learning_rate, use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train_selected, y_train_encoded)\n",
    "\n",
    "# Avaliação no conjunto de validação\n",
    "print(\"Avaliando no conjunto de validação...\")\n",
    "y_pred_val = model.predict(X_val_selected)\n",
    "val_accuracy = accuracy_score(y_val_encoded, y_pred_val)\n",
    "val_f1 = f1_score(y_val_encoded, y_pred_val, average='macro')  \n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "y_pred_test = model.predict(X_test_selected)\n",
    "\n",
    "y_pred_test_decoded = enc2.inverse_transform(y_pred_test)\n",
    "\n",
    "## formating the submission file\n",
    "X_test['Claim Injury Type'] = y_pred_test_decoded\n",
    "sample_submission = X_test[['Claim Injury Type']].set_index(X_test.index)\n",
    "sample_submission.to_csv('submission_xgboost2.csv')\n",
    "\n",
    "joblib.dump(model, 'xgboost_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  warnings.warn(smsg, UserWarning)\n",
    "Número de features selecionadas: 9\n",
    "Features selecionadas: ['Average Weekly Wage', 'C-2 Date', 'C-3 Date', 'First Hearing Date', 'IME-4 Count', 'Attorney/Representative_False', 'Attorney/Representative_True', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF']\n",
    "Treinando o modelo...\n",
    "Avaliando no conjunto de validação...\n",
    "Validation Accuracy: 0.7765\n",
    "Validation F1 Score: 0.7295\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:425: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:426: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:440: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(mean_value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE...\n",
      "Training the XGBoost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:34:22] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on the validation set...\n",
      "Validation Accuracy: 0.6272\n",
      "Validation F1 Score: 0.2901\n",
      "XGBoost model with SMOTE training and prediction completed.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure the indices are reset\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "learning_rate = 0.7  \n",
    "\n",
    "# Preprocessing\n",
    "print(\"Preprocessing...\")\n",
    "X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "X_train, X_val = outliers_iqr(X_train, X_val, X_train.columns)\n",
    "\n",
    "# Preprocess test data\n",
    "X_test = test_data[~(test_data.drop(columns=['Assembly Date']).isna().all(axis=1) & test_data['Assembly Date'].notna())]\n",
    "X_test = drop_description_columns_Test(X_test)\n",
    "X_test = preprocessing_dum_test(X_test)\n",
    "X_test = scaling_encoding_test(X_test)\n",
    "\n",
    "# Encode labels\n",
    "enc2 = LabelEncoder()\n",
    "enc2.fit(y_train)\n",
    "\n",
    "# Encode y_train and y_val\n",
    "y_train_encoded = enc2.transform(y_train)\n",
    "y_val_encoded = enc2.transform(y_val)\n",
    "\n",
    "# Apply SMOTE on the training data\n",
    "print(\"Applying SMOTE...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train_encoded)\n",
    "\n",
    "# Feature selection using predefined features\n",
    "selected_features = ['Average Weekly Wage', 'C-2 Date', 'C-3 Date', 'First Hearing Date', \n",
    "                     'IME-4 Count', 'Attorney/Representative_False', 'Attorney/Representative_True', \n",
    "                     'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF']\n",
    "\n",
    "X_train_selected = X_train_smote[selected_features]\n",
    "X_val_selected = X_val[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Train the XGBoost model\n",
    "print(\"Training the XGBoost model...\")\n",
    "model = XGBClassifier(learning_rate=learning_rate, use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train_selected, y_train_smote)\n",
    "\n",
    "# Evaluate on validation data\n",
    "print(\"Evaluating on the validation set...\")\n",
    "y_pred_val = model.predict(X_val_selected)\n",
    "val_accuracy = accuracy_score(y_val_encoded, y_pred_val)\n",
    "val_f1 = f1_score(y_val_encoded, y_pred_val, average='macro')\n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = model.predict(X_test_selected)\n",
    "y_pred_test_decoded = enc2.inverse_transform(y_pred_test)\n",
    "\n",
    "# Format the submission file\n",
    "X_test['Claim Injury Type'] = y_pred_test_decoded\n",
    "sample_submission = X_test[['Claim Injury Type']].set_index(X_test.index)\n",
    "sample_submission.to_csv('submission_xgboost_smote.csv')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'xgboost_model_smote.pkl')\n",
    "\n",
    "print(\"XGBoost model with SMOTE training and prediction completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to Evaluate XGBoost for different Learning Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:425: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:426: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\inesm\\OneDrive\\Documentos\\GitHub\\ML_Group36\\src\\Preprocessing_functions.py:440: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(mean_value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features RFECV...\n",
      "Training model with learning rate: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:15:38] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Accuracy for lr=0.2: 0.7528\n",
      "Validation F1 Score for lr=0.2: 0.2992\n",
      "Saved predictions to submission_xgboost_lr_0.2.csv\n",
      "Training model with learning rate: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:15:50] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Accuracy for lr=0.4: 0.7522\n",
      "Validation F1 Score for lr=0.4: 0.3000\n",
      "Saved predictions to submission_xgboost_lr_0.4.csv\n",
      "Training model with learning rate: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:16:03] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Accuracy for lr=0.5: 0.7522\n",
      "Validation F1 Score for lr=0.5: 0.3002\n",
      "Saved predictions to submission_xgboost_lr_0.5.csv\n",
      "Training model with learning rate: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:16:17] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Accuracy for lr=0.7: 0.7518\n",
      "Validation F1 Score for lr=0.7: 0.3011\n",
      "Saved predictions to submission_xgboost_lr_0.7.csv\n",
      "Training model with learning rate: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesm\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:16:31] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "Validation Accuracy for lr=0.8: 0.7510\n",
      "Validation F1 Score for lr=0.8: 0.3008\n",
      "Saved predictions to submission_xgboost_lr_0.8.csv\n",
      "Learning Rate Evaluation Results:\n",
      "   Learning Rate  Validation Accuracy  Validation F1 Score\n",
      "0            0.2             0.752757             0.299214\n",
      "1            0.4             0.752217             0.300004\n",
      "2            0.5             0.752208             0.300182\n",
      "3            0.7             0.751764             0.301075\n",
      "4            0.8             0.750997             0.300825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Define the learning rates to evaluate\n",
    "learning_rates = [ 0.2, 0.4, 0.5, 0.7, 0.8]\n",
    "\n",
    "# Dictionary to store results for each learning rate\n",
    "results = []\n",
    "\n",
    "# preprocessing\n",
    "print(\"preprocessing...\")\n",
    "X_train, X_val = preprocessing_dum(X_train, X_val)\n",
    "X_train, X_val = scaling_encoding(X_train, X_val)\n",
    "X_train,X_val=outliers_iqr(X_train,X_val,X_train.columns)\n",
    "\n",
    "#preprocessing test data\n",
    "X_test = test_data[~(test_data.drop(columns=['Assembly Date']).isna().all(axis=1) & test_data['Assembly Date'].notna())] \n",
    "X_test= drop_description_columns_Test(X_test)\n",
    "X_test= preprocessing_dum_test(X_test)\n",
    "X_test = scaling_encoding_test(X_test)\n",
    "\n",
    "enc2 = LabelEncoder()\n",
    "enc2.fit(y_train)\n",
    "\n",
    "# Codifica os valores de y_train e y_val\n",
    "y_train_encoded = enc2.transform(y_train)\n",
    "y_val_encoded = enc2.transform(y_val)\n",
    "\n",
    "# RFECV\n",
    "print(\"Selecting features RFECV...\")\n",
    "selected_features = ['Average Weekly Wage', 'C-2 Date', 'C-3 Date', 'First Hearing Date', \n",
    "                    'IME-4 Count', 'Attorney/Representative_False', 'Attorney/Representative_True', \n",
    "                    'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF']\n",
    "\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_val_selected = X_val[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Loop through each learning rate\n",
    "for lr in learning_rates:\n",
    "    print(f\"Training model with learning rate: {lr}\")\n",
    "    \n",
    "    # Train the model\n",
    "    model = XGBClassifier(learning_rate=lr, use_label_encoder=False, eval_metric='mlogloss')\n",
    "    model.fit(X_train_selected, y_train_encoded)\n",
    "    \n",
    "    # Evaluate on validation data\n",
    "    print(\"Evaluating on validation set...\")\n",
    "    y_pred_val = model.predict(X_val_selected)\n",
    "    val_accuracy = accuracy_score(y_val_encoded, y_pred_val)\n",
    "    val_f1 = f1_score(y_val_encoded, y_pred_val, average='macro')  \n",
    "    \n",
    "    print(f\"Validation Accuracy for lr={lr}: {val_accuracy:.4f}\")\n",
    "    print(f\"Validation F1 Score for lr={lr}: {val_f1:.4f}\")\n",
    "    \n",
    "    \n",
    "    # Store the results\n",
    "    results.append({'Learning Rate': lr, 'Validation Accuracy': val_accuracy, 'Validation F1 Score': val_f1})\n",
    "    \n",
    "    # Predict on test data for the current model\n",
    "    y_pred_test = model.predict(X_test_selected)\n",
    "    y_pred_test_decoded = enc2.inverse_transform(y_pred_test)\n",
    "    \n",
    "    # Format the submission file for the current learning rate\n",
    "    X_test['Claim Injury Type'] = y_pred_test_decoded\n",
    "    sample_submission = X_test[['Claim Injury Type']].set_index(X_test.index)\n",
    "    submission_filename = f'submission_xgboost_lr_{lr}.csv'\n",
    "    sample_submission.to_csv(submission_filename)\n",
    "    print(f\"Saved predictions to {submission_filename}\")\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "print(\"Learning Rate Evaluation Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('learning_rate_evaluation_results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
